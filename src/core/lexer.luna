# (c) 2026 Luna Ecosystem. Lead Architect: LMDtokyo. All rights reserved.
# Licensed under GPLv3. See LICENSE file.

# =============================================================================
# Luna Self-Hosting Lexer v2.0
# =============================================================================
# This is the first step toward Luna compiling itself.
# A fast, streaming lexer for Luna source code.
#
# Features:
# - Zero-copy string handling where possible
# - Single-pass tokenization
# - Full Luna v1.9+ syntax support
# - Position tracking for error messages
# =============================================================================

# === TOKEN TYPES ===
# Token type enumeration using integer constants

# Literals
const TOKEN_EOF: int = 0
const TOKEN_INT: int = 1
const TOKEN_FLOAT: int = 2
const TOKEN_STRING: int = 3
const TOKEN_CHAR: int = 4
const TOKEN_BOOL: int = 5

# Identifiers and Keywords
const TOKEN_IDENT: int = 10
const TOKEN_KEYWORD: int = 11

# Operators
const TOKEN_PLUS: int = 20          # +
const TOKEN_MINUS: int = 21         # -
const TOKEN_STAR: int = 22          # *
const TOKEN_SLASH: int = 23         # /
const TOKEN_PERCENT: int = 24       # %
const TOKEN_AMPERSAND: int = 25     # &
const TOKEN_PIPE: int = 26          # |
const TOKEN_CARET: int = 27         # ^
const TOKEN_TILDE: int = 28         # ~
const TOKEN_BANG: int = 29          # !
const TOKEN_LT: int = 30            # <
const TOKEN_GT: int = 31            # >
const TOKEN_EQ: int = 32            # =
const TOKEN_DOT: int = 33           # .
const TOKEN_AT: int = 34            # @
const TOKEN_HASH: int = 35          # #

# Compound Operators
const TOKEN_PLUS_EQ: int = 40       # +=
const TOKEN_MINUS_EQ: int = 41      # -=
const TOKEN_STAR_EQ: int = 42       # *=
const TOKEN_SLASH_EQ: int = 43      # /=
const TOKEN_EQ_EQ: int = 44         # ==
const TOKEN_BANG_EQ: int = 45       # !=
const TOKEN_LT_EQ: int = 46         # <=
const TOKEN_GT_EQ: int = 47         # >=
const TOKEN_AND_AND: int = 48       # &&
const TOKEN_OR_OR: int = 49         # ||
const TOKEN_LT_LT: int = 50         # <<
const TOKEN_GT_GT: int = 51         # >>
const TOKEN_ARROW: int = 52         # ->
const TOKEN_FAT_ARROW: int = 53     # =>
const TOKEN_DOT_DOT: int = 54       # ..
const TOKEN_DOT_DOT_EQ: int = 55    # ..=
const TOKEN_COLON_COLON: int = 56   # ::

# Delimiters
const TOKEN_LPAREN: int = 60        # (
const TOKEN_RPAREN: int = 61        # )
const TOKEN_LBRACKET: int = 62      # [
const TOKEN_RBRACKET: int = 63      # ]
const TOKEN_LBRACE: int = 64        # {
const TOKEN_RBRACE: int = 65        # }
const TOKEN_COMMA: int = 66         # ,
const TOKEN_COLON: int = 67         # :
const TOKEN_SEMICOLON: int = 68     # ;
const TOKEN_NEWLINE: int = 69       # \n (significant in Luna)

# Special
const TOKEN_INDENT: int = 70        # Indentation increase
const TOKEN_DEDENT: int = 71        # Indentation decrease
const TOKEN_ERROR: int = 99         # Lexical error

# === KEYWORD TABLE ===
# Keywords are identified by hash for O(1) lookup

const KW_FN: int = 1
const KW_LET: int = 2
const KW_CONST: int = 3
const KW_MEOW: int = 4
const KW_IF: int = 5
const KW_ELSE: int = 6
const KW_ECLIPSE: int = 7
const KW_ORBIT: int = 8
const KW_WHILE: int = 9
const KW_RETURN: int = 10
const KW_BREAK: int = 11
const KW_CONTINUE: int = 12
const KW_MATCH: int = 13
const KW_STRUCT: int = 14
const KW_ENUM: int = 15
const KW_IMPL: int = 16
const KW_TRAIT: int = 17
const KW_USE: int = 18
const KW_IMPORT: int = 19
const KW_EXPORT: int = 20
const KW_PUB: int = 21
const KW_MUT: int = 22
const KW_REF: int = 23
const KW_UNSAFE: int = 24
const KW_ASM: int = 25
const KW_PASS: int = 26
const KW_TRUE: int = 27
const KW_FALSE: int = 28
const KW_NIL: int = 29
const KW_IN: int = 30
const KW_AS: int = 31
const KW_AND: int = 32
const KW_OR: int = 33
const KW_NOT: int = 34
const KW_NOVA: int = 35
const KW_GUARD: int = 36
const KW_SHINE: int = 37
const KW_PHASE: int = 38

# === SOURCE POSITION ===
struct SourcePos
    line: int
    column: int
    offset: int

fn source_pos_new(@line: int, @col: int, @offset: int) -> SourcePos
    return SourcePos { line: @line, column: @col, offset: @offset }

# === TOKEN STRUCTURE ===
struct Token
    kind: int           # TOKEN_* constant
    start: int          # Start offset in source
    length: int         # Length of token text
    line: int           # Line number (1-based)
    column: int         # Column number (1-based)
    int_value: int      # For integer literals
    float_value: float  # For float literals
    keyword_id: int     # For keywords (KW_* constant)

fn token_new(@kind: int, @start: int, @len: int, @line: int, @col: int) -> Token
    return Token {
        kind: @kind,
        start: @start,
        length: @len,
        line: @line,
        column: @col,
        int_value: 0,
        float_value: 0.0,
        keyword_id: 0
    }

# === LEXER STATE ===
struct Lexer
    source: str         # Source code (pointer to first char)
    source_len: int     # Total length of source
    pos: int            # Current position
    line: int           # Current line (1-based)
    column: int         # Current column (1-based)
    indent_stack: [int; 64]  # Stack of indentation levels
    indent_depth: int   # Current depth in indent_stack
    pending_dedents: int     # Number of DEDENT tokens to emit
    at_line_start: int  # 1 if at start of line

# === LEXER CREATION ===
fn lexer_new(@src: str, @src_len: int) -> Lexer
    @lex = Lexer {
        source: @src,
        source_len: @src_len,
        pos: 0,
        line: 1,
        column: 1,
        indent_stack: [0; 64],
        indent_depth: 0,
        pending_dedents: 0,
        at_line_start: 1
    }
    @lex.indent_stack[0] = 0  # Base indentation level
    return @lex

# === CHARACTER HELPERS ===
#[inline]
fn is_whitespace(@ch: int) -> int
    return @ch == 32 || @ch == 9  # space or tab

#[inline]
fn is_newline(@ch: int) -> int
    return @ch == 10 || @ch == 13  # \n or \r

#[inline]
fn is_digit(@ch: int) -> int
    return @ch >= 48 && @ch <= 57  # '0'-'9'

#[inline]
fn is_hex_digit(@ch: int) -> int
    return is_digit(@ch) || (@ch >= 65 && @ch <= 70) || (@ch >= 97 && @ch <= 102)

#[inline]
fn is_alpha(@ch: int) -> int
    return (@ch >= 65 && @ch <= 90) || (@ch >= 97 && @ch <= 122) || @ch == 95  # A-Z, a-z, _

#[inline]
fn is_alnum(@ch: int) -> int
    return is_alpha(@ch) || is_digit(@ch)

# === LEXER CORE OPERATIONS ===

# Peek current character without advancing
#[inline]
fn lexer_peek(@lex: Lexer) -> int
    if @lex.pos >= @lex.source_len
        return 0  # EOF
    unsafe
        return volatile_read(@lex.source + @lex.pos)

# Peek next character (one ahead)
#[inline]
fn lexer_peek_next(@lex: Lexer) -> int
    if @lex.pos + 1 >= @lex.source_len
        return 0
    unsafe
        return volatile_read(@lex.source + @lex.pos + 1)

# Advance position by one character
#[inline]
fn lexer_advance(@lex: Lexer) -> int
    @ch = lexer_peek(@lex)
    if @ch != 0
        @lex.pos = @lex.pos + 1
        if is_newline(@ch)
            @lex.line = @lex.line + 1
            @lex.column = 1
            @lex.at_line_start = 1
        else
            @lex.column = @lex.column + 1
    return @ch

# Skip whitespace (but not newlines - they're significant)
fn lexer_skip_whitespace(@lex: Lexer)
    orbit _ in 0..@lex.source_len
        @ch = lexer_peek(@lex)
        if @ch == 32 || @ch == 9  # space or tab
            lexer_advance(@lex)
        else
            break

# Skip to end of line (for comments)
fn lexer_skip_line(@lex: Lexer)
    orbit _ in 0..@lex.source_len
        @ch = lexer_peek(@lex)
        if @ch == 0 || is_newline(@ch)
            break
        lexer_advance(@lex)

# === INDENTATION HANDLING ===
# Luna uses significant whitespace like Python

fn lexer_handle_indentation(@lex: Lexer) -> Token
    if @lex.at_line_start == 0
        return token_new(TOKEN_ERROR, @lex.pos, 0, @lex.line, @lex.column)

    # Count leading spaces/tabs
    @indent = 0
    @start_pos = @lex.pos
    orbit _ in 0..@lex.source_len
        @ch = lexer_peek(@lex)
        if @ch == 32  # space
            @indent = @indent + 1
            lexer_advance(@lex)
        eclipse if @ch == 9  # tab = 4 spaces
            @indent = @indent + 4
            lexer_advance(@lex)
        else
            break

    @lex.at_line_start = 0

    # Skip blank lines and comments
    @ch = lexer_peek(@lex)
    if is_newline(@ch) || @ch == 35  # newline or comment
        return token_new(TOKEN_ERROR, @start_pos, 0, @lex.line, @lex.column)  # Signal to continue

    # Compare with current indentation level
    @current_indent = @lex.indent_stack[@lex.indent_depth]

    if @indent > @current_indent
        # Indent: push new level
        @lex.indent_depth = @lex.indent_depth + 1
        if @lex.indent_depth < 64
            @lex.indent_stack[@lex.indent_depth] = @indent
        return token_new(TOKEN_INDENT, @start_pos, @indent - @current_indent, @lex.line, 1)

    eclipse if @indent < @current_indent
        # Dedent: pop levels until we match
        @dedents = 0
        orbit _ in 0..64
            if @lex.indent_depth == 0
                break
            if @lex.indent_stack[@lex.indent_depth] <= @indent
                break
            @lex.indent_depth = @lex.indent_depth - 1
            @dedents = @dedents + 1

        if @dedents > 1
            @lex.pending_dedents = @dedents - 1
        return token_new(TOKEN_DEDENT, @start_pos, 1, @lex.line, 1)

    # Same level - no token needed
    return token_new(TOKEN_ERROR, @start_pos, 0, @lex.line, @lex.column)

# === NUMBER LEXING ===

fn lexer_scan_number(@lex: Lexer) -> Token
    @start = @lex.pos
    @start_col = @lex.column
    @is_float = 0
    @is_hex = 0
    @is_bin = 0

    # Check for hex (0x) or binary (0b)
    if lexer_peek(@lex) == 48  # '0'
        @next = lexer_peek_next(@lex)
        if @next == 120 || @next == 88  # 'x' or 'X'
            lexer_advance(@lex)  # skip '0'
            lexer_advance(@lex)  # skip 'x'
            @is_hex = 1
        eclipse if @next == 98 || @next == 66  # 'b' or 'B'
            lexer_advance(@lex)
            lexer_advance(@lex)
            @is_bin = 1

    if @is_hex
        # Hex number
        orbit _ in 0..64
            if is_hex_digit(lexer_peek(@lex)) == 0
                break
            lexer_advance(@lex)
    eclipse if @is_bin
        # Binary number
        orbit _ in 0..64
            @ch = lexer_peek(@lex)
            if @ch != 48 && @ch != 49  # not '0' or '1'
                break
            lexer_advance(@lex)
    else
        # Decimal number
        orbit _ in 0..64
            if is_digit(lexer_peek(@lex)) == 0
                break
            lexer_advance(@lex)

        # Check for decimal point
        if lexer_peek(@lex) == 46 && is_digit(lexer_peek_next(@lex))  # '.'
            @is_float = 1
            lexer_advance(@lex)  # skip '.'
            orbit _ in 0..64
                if is_digit(lexer_peek(@lex)) == 0
                    break
                lexer_advance(@lex)

        # Check for exponent
        @ch = lexer_peek(@lex)
        if @ch == 101 || @ch == 69  # 'e' or 'E'
            @is_float = 1
            lexer_advance(@lex)
            @ch = lexer_peek(@lex)
            if @ch == 43 || @ch == 45  # '+' or '-'
                lexer_advance(@lex)
            orbit _ in 0..64
                if is_digit(lexer_peek(@lex)) == 0
                    break
                lexer_advance(@lex)

    @length = @lex.pos - @start
    @tok = token_new(if @is_float then TOKEN_FLOAT else TOKEN_INT, @start, @length, @lex.line, @start_col)

    # Parse the value
    if @is_float == 0
        @tok.int_value = lexer_parse_int(@lex.source, @start, @length, @is_hex, @is_bin)

    return @tok

# Parse integer from string slice
fn lexer_parse_int(@src: str, @start: int, @len: int, @is_hex: int, @is_bin: int) -> int
    @value = 0
    @offset = @start

    if @is_hex
        @offset = @offset + 2  # skip "0x"
        orbit _ in 0..@len - 2
            @ch = 0
            unsafe
                @ch = volatile_read(@src + @offset)
            @digit = 0
            if @ch >= 48 && @ch <= 57
                @digit = @ch - 48
            eclipse if @ch >= 65 && @ch <= 70
                @digit = @ch - 55
            eclipse if @ch >= 97 && @ch <= 102
                @digit = @ch - 87
            @value = (@value << 4) | @digit
            @offset = @offset + 1
    eclipse if @is_bin
        @offset = @offset + 2  # skip "0b"
        orbit _ in 0..@len - 2
            @ch = 0
            unsafe
                @ch = volatile_read(@src + @offset)
            @value = (@value << 1) | (@ch - 48)
            @offset = @offset + 1
    else
        orbit _ in 0..@len
            @ch = 0
            unsafe
                @ch = volatile_read(@src + @offset)
            @value = @value * 10 + (@ch - 48)
            @offset = @offset + 1

    return @value

# === STRING LEXING ===

fn lexer_scan_string(@lex: Lexer) -> Token
    @start = @lex.pos
    @start_col = @lex.column
    @quote = lexer_advance(@lex)  # consume opening quote

    orbit _ in 0..65536  # max string length
        @ch = lexer_peek(@lex)
        if @ch == 0 || is_newline(@ch)
            # Unterminated string
            return token_new(TOKEN_ERROR, @start, @lex.pos - @start, @lex.line, @start_col)

        if @ch == @quote
            lexer_advance(@lex)  # consume closing quote
            break

        if @ch == 92  # backslash - escape sequence
            lexer_advance(@lex)
            lexer_advance(@lex)  # skip escaped char
        else
            lexer_advance(@lex)

    return token_new(TOKEN_STRING, @start, @lex.pos - @start, @lex.line, @start_col)

# === IDENTIFIER AND KEYWORD LEXING ===

fn lexer_scan_identifier(@lex: Lexer) -> Token
    @start = @lex.pos
    @start_col = @lex.column

    # First character (already verified as alpha or @)
    @has_at = 0
    if lexer_peek(@lex) == 64  # '@'
        @has_at = 1
        lexer_advance(@lex)

    # Consume identifier characters
    orbit _ in 0..256  # max identifier length
        if is_alnum(lexer_peek(@lex)) == 0
            break
        lexer_advance(@lex)

    @length = @lex.pos - @start
    @tok = token_new(TOKEN_IDENT, @start, @length, @lex.line, @start_col)

    # Check if it's a keyword (only if no @ prefix)
    if @has_at == 0
        @kw = lexer_match_keyword(@lex.source, @start, @length)
        if @kw != 0
            @tok.kind = TOKEN_KEYWORD
            @tok.keyword_id = @kw

            # Special case: true/false are booleans
            if @kw == KW_TRUE || @kw == KW_FALSE
                @tok.kind = TOKEN_BOOL
                @tok.int_value = if @kw == KW_TRUE then 1 else 0

    return @tok

# Match keyword using hash comparison
fn lexer_match_keyword(@src: str, @start: int, @len: int) -> int
    # Simple keyword matching using first character + length
    @first = 0
    unsafe
        @first = volatile_read(@src + @start)

    # Keywords by first letter
    match @first
        102  # 'f'
            if @len == 2 && lexer_str_eq(@src, @start, "fn", 2)
                return KW_FN
            if @len == 5 && lexer_str_eq(@src, @start, "false", 5)
                return KW_FALSE

        108  # 'l'
            if @len == 3 && lexer_str_eq(@src, @start, "let", 3)
                return KW_LET

        99   # 'c'
            if @len == 5 && lexer_str_eq(@src, @start, "const", 5)
                return KW_CONST
            if @len == 8 && lexer_str_eq(@src, @start, "continue", 8)
                return KW_CONTINUE

        109  # 'm'
            if @len == 4 && lexer_str_eq(@src, @start, "meow", 4)
                return KW_MEOW
            if @len == 5 && lexer_str_eq(@src, @start, "match", 5)
                return KW_MATCH
            if @len == 3 && lexer_str_eq(@src, @start, "mut", 3)
                return KW_MUT

        105  # 'i'
            if @len == 2 && lexer_str_eq(@src, @start, "if", 2)
                return KW_IF
            if @len == 4 && lexer_str_eq(@src, @start, "impl", 4)
                return KW_IMPL
            if @len == 6 && lexer_str_eq(@src, @start, "import", 6)
                return KW_IMPORT
            if @len == 2 && lexer_str_eq(@src, @start, "in", 2)
                return KW_IN

        101  # 'e'
            if @len == 4 && lexer_str_eq(@src, @start, "else", 4)
                return KW_ELSE
            if @len == 7 && lexer_str_eq(@src, @start, "eclipse", 7)
                return KW_ECLIPSE
            if @len == 4 && lexer_str_eq(@src, @start, "enum", 4)
                return KW_ENUM
            if @len == 6 && lexer_str_eq(@src, @start, "export", 6)
                return KW_EXPORT

        111  # 'o'
            if @len == 5 && lexer_str_eq(@src, @start, "orbit", 5)
                return KW_ORBIT
            if @len == 2 && lexer_str_eq(@src, @start, "or", 2)
                return KW_OR

        119  # 'w'
            if @len == 5 && lexer_str_eq(@src, @start, "while", 5)
                return KW_WHILE

        114  # 'r'
            if @len == 6 && lexer_str_eq(@src, @start, "return", 6)
                return KW_RETURN
            if @len == 3 && lexer_str_eq(@src, @start, "ref", 3)
                return KW_REF

        98   # 'b'
            if @len == 5 && lexer_str_eq(@src, @start, "break", 5)
                return KW_BREAK

        115  # 's'
            if @len == 6 && lexer_str_eq(@src, @start, "struct", 6)
                return KW_STRUCT
            if @len == 5 && lexer_str_eq(@src, @start, "shine", 5)
                return KW_SHINE

        116  # 't'
            if @len == 5 && lexer_str_eq(@src, @start, "trait", 5)
                return KW_TRAIT
            if @len == 4 && lexer_str_eq(@src, @start, "true", 4)
                return KW_TRUE

        117  # 'u'
            if @len == 3 && lexer_str_eq(@src, @start, "use", 3)
                return KW_USE
            if @len == 6 && lexer_str_eq(@src, @start, "unsafe", 6)
                return KW_UNSAFE

        112  # 'p'
            if @len == 3 && lexer_str_eq(@src, @start, "pub", 3)
                return KW_PUB
            if @len == 4 && lexer_str_eq(@src, @start, "pass", 4)
                return KW_PASS
            if @len == 5 && lexer_str_eq(@src, @start, "phase", 5)
                return KW_PHASE

        97   # 'a'
            if @len == 3 && lexer_str_eq(@src, @start, "asm", 3)
                return KW_ASM
            if @len == 3 && lexer_str_eq(@src, @start, "and", 3)
                return KW_AND
            if @len == 2 && lexer_str_eq(@src, @start, "as", 2)
                return KW_AS

        110  # 'n'
            if @len == 3 && lexer_str_eq(@src, @start, "nil", 3)
                return KW_NIL
            if @len == 3 && lexer_str_eq(@src, @start, "not", 3)
                return KW_NOT
            if @len == 4 && lexer_str_eq(@src, @start, "nova", 4)
                return KW_NOVA

        103  # 'g'
            if @len == 5 && lexer_str_eq(@src, @start, "guard", 5)
                return KW_GUARD

    return 0  # Not a keyword

# String equality helper
fn lexer_str_eq(@src: str, @start: int, @target: str, @len: int) -> int
    orbit @i in 0..@len
        @a = 0
        @b = 0
        unsafe
            @a = volatile_read(@src + @start + @i)
            @b = volatile_read(@target + @i)
        if @a != @b
            return 0
    return 1

# === OPERATOR LEXING ===

fn lexer_scan_operator(@lex: Lexer) -> Token
    @start = @lex.pos
    @start_col = @lex.column
    @ch = lexer_advance(@lex)
    @next = lexer_peek(@lex)

    match @ch
        43   # '+'
            if @next == 61  # '='
                lexer_advance(@lex)
                return token_new(TOKEN_PLUS_EQ, @start, 2, @lex.line, @start_col)
            return token_new(TOKEN_PLUS, @start, 1, @lex.line, @start_col)

        45   # '-'
            if @next == 61  # '='
                lexer_advance(@lex)
                return token_new(TOKEN_MINUS_EQ, @start, 2, @lex.line, @start_col)
            if @next == 62  # '>'
                lexer_advance(@lex)
                return token_new(TOKEN_ARROW, @start, 2, @lex.line, @start_col)
            return token_new(TOKEN_MINUS, @start, 1, @lex.line, @start_col)

        42   # '*'
            if @next == 61  # '='
                lexer_advance(@lex)
                return token_new(TOKEN_STAR_EQ, @start, 2, @lex.line, @start_col)
            return token_new(TOKEN_STAR, @start, 1, @lex.line, @start_col)

        47   # '/'
            if @next == 61  # '='
                lexer_advance(@lex)
                return token_new(TOKEN_SLASH_EQ, @start, 2, @lex.line, @start_col)
            return token_new(TOKEN_SLASH, @start, 1, @lex.line, @start_col)

        37   # '%'
            return token_new(TOKEN_PERCENT, @start, 1, @lex.line, @start_col)

        38   # '&'
            if @next == 38  # '&'
                lexer_advance(@lex)
                return token_new(TOKEN_AND_AND, @start, 2, @lex.line, @start_col)
            return token_new(TOKEN_AMPERSAND, @start, 1, @lex.line, @start_col)

        124  # '|'
            if @next == 124  # '|'
                lexer_advance(@lex)
                return token_new(TOKEN_OR_OR, @start, 2, @lex.line, @start_col)
            return token_new(TOKEN_PIPE, @start, 1, @lex.line, @start_col)

        94   # '^'
            return token_new(TOKEN_CARET, @start, 1, @lex.line, @start_col)

        126  # '~'
            return token_new(TOKEN_TILDE, @start, 1, @lex.line, @start_col)

        33   # '!'
            if @next == 61  # '='
                lexer_advance(@lex)
                return token_new(TOKEN_BANG_EQ, @start, 2, @lex.line, @start_col)
            return token_new(TOKEN_BANG, @start, 1, @lex.line, @start_col)

        60   # '<'
            if @next == 61  # '='
                lexer_advance(@lex)
                return token_new(TOKEN_LT_EQ, @start, 2, @lex.line, @start_col)
            if @next == 60  # '<'
                lexer_advance(@lex)
                return token_new(TOKEN_LT_LT, @start, 2, @lex.line, @start_col)
            return token_new(TOKEN_LT, @start, 1, @lex.line, @start_col)

        62   # '>'
            if @next == 61  # '='
                lexer_advance(@lex)
                return token_new(TOKEN_GT_EQ, @start, 2, @lex.line, @start_col)
            if @next == 62  # '>'
                lexer_advance(@lex)
                return token_new(TOKEN_GT_GT, @start, 2, @lex.line, @start_col)
            return token_new(TOKEN_GT, @start, 1, @lex.line, @start_col)

        61   # '='
            if @next == 61  # '='
                lexer_advance(@lex)
                return token_new(TOKEN_EQ_EQ, @start, 2, @lex.line, @start_col)
            if @next == 62  # '>'
                lexer_advance(@lex)
                return token_new(TOKEN_FAT_ARROW, @start, 2, @lex.line, @start_col)
            return token_new(TOKEN_EQ, @start, 1, @lex.line, @start_col)

        46   # '.'
            if @next == 46  # '.'
                lexer_advance(@lex)
                if lexer_peek(@lex) == 61  # '='
                    lexer_advance(@lex)
                    return token_new(TOKEN_DOT_DOT_EQ, @start, 3, @lex.line, @start_col)
                return token_new(TOKEN_DOT_DOT, @start, 2, @lex.line, @start_col)
            return token_new(TOKEN_DOT, @start, 1, @lex.line, @start_col)

        58   # ':'
            if @next == 58  # ':'
                lexer_advance(@lex)
                return token_new(TOKEN_COLON_COLON, @start, 2, @lex.line, @start_col)
            return token_new(TOKEN_COLON, @start, 1, @lex.line, @start_col)

    return token_new(TOKEN_ERROR, @start, 1, @lex.line, @start_col)

# === MAIN LEXER FUNCTION ===

fn lexer_next_token(@lex: Lexer) -> Token
    # Handle pending dedents
    if @lex.pending_dedents > 0
        @lex.pending_dedents = @lex.pending_dedents - 1
        return token_new(TOKEN_DEDENT, @lex.pos, 0, @lex.line, @lex.column)

    # Handle indentation at line start
    if @lex.at_line_start
        @indent_tok = lexer_handle_indentation(@lex)
        if @indent_tok.kind == TOKEN_INDENT || @indent_tok.kind == TOKEN_DEDENT
            return @indent_tok
        # Otherwise continue to regular tokenization

    # Skip whitespace (but not newlines)
    lexer_skip_whitespace(@lex)

    # Check for EOF
    if @lex.pos >= @lex.source_len
        return token_new(TOKEN_EOF, @lex.pos, 0, @lex.line, @lex.column)

    @ch = lexer_peek(@lex)

    # Newline
    if is_newline(@ch)
        @start = @lex.pos
        @start_col = @lex.column
        lexer_advance(@lex)
        # Handle CRLF
        if @ch == 13 && lexer_peek(@lex) == 10
            lexer_advance(@lex)
        return token_new(TOKEN_NEWLINE, @start, 1, @lex.line - 1, @start_col)

    # Comment
    if @ch == 35  # '#'
        lexer_skip_line(@lex)
        return lexer_next_token(@lex)  # Recurse to get next real token

    # String
    if @ch == 34 || @ch == 39  # '"' or '\''
        return lexer_scan_string(@lex)

    # Number
    if is_digit(@ch)
        return lexer_scan_number(@lex)

    # Identifier or keyword (including @ prefix for variables)
    if is_alpha(@ch) || @ch == 64  # alpha or '@'
        return lexer_scan_identifier(@lex)

    # Delimiters
    match @ch
        40   # '('
            @start = @lex.pos
            lexer_advance(@lex)
            return token_new(TOKEN_LPAREN, @start, 1, @lex.line, @lex.column - 1)
        41   # ')'
            @start = @lex.pos
            lexer_advance(@lex)
            return token_new(TOKEN_RPAREN, @start, 1, @lex.line, @lex.column - 1)
        91   # '['
            @start = @lex.pos
            lexer_advance(@lex)
            return token_new(TOKEN_LBRACKET, @start, 1, @lex.line, @lex.column - 1)
        93   # ']'
            @start = @lex.pos
            lexer_advance(@lex)
            return token_new(TOKEN_RBRACKET, @start, 1, @lex.line, @lex.column - 1)
        123  # '{'
            @start = @lex.pos
            lexer_advance(@lex)
            return token_new(TOKEN_LBRACE, @start, 1, @lex.line, @lex.column - 1)
        125  # '}'
            @start = @lex.pos
            lexer_advance(@lex)
            return token_new(TOKEN_RBRACE, @start, 1, @lex.line, @lex.column - 1)
        44   # ','
            @start = @lex.pos
            lexer_advance(@lex)
            return token_new(TOKEN_COMMA, @start, 1, @lex.line, @lex.column - 1)
        59   # ';'
            @start = @lex.pos
            lexer_advance(@lex)
            return token_new(TOKEN_SEMICOLON, @start, 1, @lex.line, @lex.column - 1)

    # Operators
    return lexer_scan_operator(@lex)

# === TOKENIZE ENTIRE FILE ===
# Returns array of tokens

fn lexer_tokenize_all(@lex: Lexer, @tokens: [Token; 65536], @max_tokens: int) -> int
    @count = 0
    orbit _ in 0..@max_tokens
        @tok = lexer_next_token(@lex)
        @tokens[@count] = @tok
        @count = @count + 1

        if @tok.kind == TOKEN_EOF
            break

    return @count

# === DEBUG HELPERS ===

fn token_kind_name(@kind: int) -> str
    match @kind
        TOKEN_EOF => return "EOF"
        TOKEN_INT => return "INT"
        TOKEN_FLOAT => return "FLOAT"
        TOKEN_STRING => return "STRING"
        TOKEN_IDENT => return "IDENT"
        TOKEN_KEYWORD => return "KEYWORD"
        TOKEN_PLUS => return "PLUS"
        TOKEN_MINUS => return "MINUS"
        TOKEN_STAR => return "STAR"
        TOKEN_SLASH => return "SLASH"
        TOKEN_EQ => return "EQ"
        TOKEN_EQ_EQ => return "EQ_EQ"
        TOKEN_LPAREN => return "LPAREN"
        TOKEN_RPAREN => return "RPAREN"
        TOKEN_LBRACE => return "LBRACE"
        TOKEN_RBRACE => return "RBRACE"
        TOKEN_NEWLINE => return "NEWLINE"
        TOKEN_INDENT => return "INDENT"
        TOKEN_DEDENT => return "DEDENT"
        TOKEN_ARROW => return "ARROW"
        TOKEN_COLON => return "COLON"
        _ => return "UNKNOWN"

# === EXPORTS ===
export {
    # Types
    Token,
    Lexer,
    SourcePos,

    # Token constants
    TOKEN_EOF, TOKEN_INT, TOKEN_FLOAT, TOKEN_STRING, TOKEN_IDENT, TOKEN_KEYWORD,
    TOKEN_PLUS, TOKEN_MINUS, TOKEN_STAR, TOKEN_SLASH, TOKEN_EQ, TOKEN_EQ_EQ,
    TOKEN_LPAREN, TOKEN_RPAREN, TOKEN_LBRACE, TOKEN_RBRACE,
    TOKEN_NEWLINE, TOKEN_INDENT, TOKEN_DEDENT, TOKEN_ARROW, TOKEN_COLON,

    # Keyword constants
    KW_FN, KW_LET, KW_CONST, KW_IF, KW_ELSE, KW_ECLIPSE, KW_ORBIT,
    KW_WHILE, KW_RETURN, KW_STRUCT, KW_MATCH, KW_IMPL,

    # Functions
    lexer_new,
    lexer_next_token,
    lexer_tokenize_all,
    token_kind_name,
    token_new
}
